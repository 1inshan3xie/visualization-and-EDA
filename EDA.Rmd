---
title: "exploritory analysis"
subtitle: " Part 2"
author: "linshan"
date: "2024-09-26"
output: github_document
---
```{r setup}
library(tidyverse)
```

## Load the data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USW00022534", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2021-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = case_match(
      id, 
      "USW00094728" ~ "CentralPark_NY", 
      "USW00022534" ~ "Molokai_HI",
      "USS0023B17S" ~ "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10,
    month = lubridate::floor_date(date, unit = "month")) |>
  select(name, id, everything())
```

## Setting options

```{r eval = FALSE}
#一般画图的操作：预先设定好自己喜欢的theme和color
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal()+theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis")

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

Let us make some plots
```{r}
weather_df |> 
  ggplot(aes(x = prcp)) + 
  geom_histogram()
```
发现大部分降水集中在0附近以及500一下，但有一些很大的，接下来，看看都是什么
```{r}
weather_df |> 
  filter(prcp >= 1000)
```

```{r}
weather_df |> 
  filter(tmax >= 20, tmax <= 30) |> 
  ggplot(aes(x = tmin, y = tmax, color = name, shape = name)) + 
  geom_point(alpha = .75)
```

## group_by
```{r}
weather_df |>
  group_by(name, month)
#一共3个name，24个month 所以groupby（name，month）有72组
```

counting stuff
```{r}
weather_df |>
  group_by(month) |>
  summarize(n_obs = n())
```

```{r}
weather_df |>
  group_by(name, month) |>
  summarize(n_obs = n())
```

```{r}
weather_df |>
  count(name)
```

```{r}
weather_df |>
  pull(month) |> 
  table()
```


## 2*2 table
```{r}
weather_df |> 
  drop_na(tmax) |> 
  mutate(
    cold = case_when(
      tmax <  5 ~ "cold",
      tmax >= 5 ~ "not_cold",
      TRUE      ~ ""
  )) |> 
  group_by(name, cold) |> 
  summarize(count = n())
```

janitor::tabyl
```{r}
weather_df |> 
  drop_na(tmax) |> 
  mutate(cold = case_when(
    tmax <  5 ~ "cold",
    tmax >= 5 ~ "not_cold",
  )) |> 
  janitor::tabyl(name, cold)
```

## general numeric summaries

try other useful summaries
```{r}
weather_df |>
  group_by(name,month) |>
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE),
    mean_prec = mean(prcp, na.rm = TRUE),
    median_tmax = median(tmax, na.rm = TRUE),
    sd_tmax = sd(tmax, na.rm = TRUE))
```
If you want to summarize multiple columns using the same summary, the across function is helpful.
```{r}
weather_df |>
  group_by(name, month) |>
  summarize(across(tmin:prcp, mean))
```

summeriaze and then plot
```{r}
weather_df |>
  group_by(name, month) |>
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) |>
  ggplot(aes(x = month, y = mean_tmax, color = name)) + 
    geom_point() + geom_line()
```

format for readers
```{r}
weather_df |>
  group_by(name, month) |>
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) |> 
  pivot_wider(
    names_from = name,
    values_from = mean_tmax) |> 
  knitr::kable(digits = 1)
```

## grouped mutate
在group后再mutate的话，算出来的结果是各个分组内的
```{r}
weather_df |>
  group_by(name) |>
  mutate(
    mean_tmax = mean(tmax, na.rm = TRUE),
    centered_tmax = tmax - mean_tmax) |> 
  ggplot(aes(x = date, y = centered_tmax, color = name)) + 
    geom_point() 
```

## Windows functions
Find the hottest/coldest day
```{r}
weather_df |>
  group_by(name, month) |>
  mutate(temp_ranking = min_rank(tmax)) |>
  filter(temp_ranking < 4)
```

```{r}
weather_df |>
  group_by(name) |>
  mutate(temp_rank = min_rank(desc(tmax)))|>
  filter(temp_rank < 4)
```
min_rank 表示按从小到达排序，最小的被rank为1.
而如果在min——rank后面加上desc，则表示倒叙，最大的被rank为1

```{r}
weather_df |>
  group_by(name) |>
  filter(min_rank(tmax) < 4)
```
这样的话就可以不通过建立新变量temp_rank，也可以筛选出最大/最小的几个

## lag function
把tmax这列的变量向下移动一格，然后行程lagged_temp
```{r}
weather_df |>
  group_by(name) |>
  mutate(lagged_tmax = lag(tmax),
         temp_change = tmax - lagged_tmax) |>
  filter(min_rank(temp_change) < 3)
```

```{r}
weather_df |>
  group_by(name) |>
  mutate(lagged_tmax = lag(tmax),
         temp_change = tmax - lagged_tmax) |>
  summarize(
    sd_tmax_change = sd(temp_change, na.rm = TRUE)
  )
```

## examples using the formar data set.
For Pulse data
```{r}
library(haven)
pulse_df = read_sas("./data_import_examples/public_pulse_data.sas7bdat") |>
  janitor::clean_names() |>
  pivot_longer(
    bdi_score_bl:bdi_score_12m,
    names_to = "visit",
    values_to = "bdi_score",
    names_prefix = "bdi_score"
  ) |>
  group_by(visit) |>
  summarize(
    mean_bdi = mean(bdi_score, na.rm = TRUE),
    median_bdi = median(bdi_score, na.rm = TRUE)
  ) |>
  knitr::kable(digits = 1)
```

## litter_df
```{r}
pup_data = 
  read_csv("./data_import_examples/FAS_pups.csv", na = c("NA",".","")) |>
  janitor::clean_names() |>
  mutate(sex = recode(sex, `1` = "male", `2` = "female")) 

litters_data = read_csv("./data_import_examples/FAS_litters.csv",na = c("NA",".","")) |>
  janitor::clean_names() |>
  separate(group, into = c("dose", "day_of_tx"), sep = 3)

fas_df = left_join(pup_data, litters_data, by = "litter_number")

fas_df |>
  group_by(dose, day_of_tx) |>
  summarize(
  mean_pivot = mean(pd_pivot, na.rm = TRUE)  
  ) |>
  pivot_wider(
    names_from = day_of_tx,
    values_from = mean_pivot
  ) |>
  knitr::kable(digits = 2)
```






